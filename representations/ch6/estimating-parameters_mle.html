
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Estimating Parameters in Network Models via MLE &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   HANDS-ON NETWORK MACHINE LEARNING WITH GRASPOLOGIC AND SCIKIT-LEARN
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Front Matter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4/matrix-representations.html">
   Matrix Representations Of Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="why-embed-networks.html">
   Why embed networks?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="spectral-embedding.html">
   Spectral Embedding Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multigraph-representation-learning.html">
   Multiple-Network Representation Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="joint-representation-learning.html">
   Joint Representation Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../applications/ch8/single-vertex-nomination.html">
   Single-Network Vertex Nomination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
   Out-of-sample Embedding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
   Anomaly Detection For Timeseries of Networks
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch6/estimating-parameters_mle.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/loftusa/thesis/master?urlpath=tree/network_machine_learning_in_python/representations/ch6/estimating-parameters_mle.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#erdos-renyi-er">
   Erdös-Rényi (ER)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stochastic-block-model">
   Stochastic Block Model
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="estimating-parameters-in-network-models-via-mle">
<h1>Estimating Parameters in Network Models via MLE<a class="headerlink" href="#estimating-parameters-in-network-models-via-mle" title="Permalink to this headline">¶</a></h1>
<p>When we learned about random networks which can be described using single network models, one of the key things we covered were the <em>parameters</em> that define the underlying random networks. If we see a network which is a realization of a random network, we do <em>not</em>, in practice, know what those parameters that describe the random network are. However, we have a slight problem, because learning about the underlying random network <em>requires</em> us to have some understanding of the parameters that define it. What are we to do?</p>
<p>To overcome this hurdle, we must <em>estimate</em> the parameters of the underlying random network. At a very high level, <strong>estimation</strong> is a procedure to calculate properties about a random variable (or a set of random variables) using only the data we are given: finitely many (in network statistics, often just one) samples which we assume are realizations of the random variable we want to learn about. Here, what we want to obtain are ways in which we can <em>estimate</em> the parameters of the underlying random network, when we have a realization of a random network.</p>
<div class="section" id="erdos-renyi-er">
<h2>Erdös-Rényi (ER)<a class="headerlink" href="#erdos-renyi-er" title="Permalink to this headline">¶</a></h2>
<p>Recall that the Erdös-Rényi (ER) network has a single parameter: the probability of each edge existing, which we termed <span class="math notranslate nohighlight">\(p\)</span>. Due to the simplicity of a random network which is ER, we can resort to the Maximum Likelihood technique we described above, and it turns out we obtain virtually the same result. We find that the best estimate of the probability of an edge existing in an ER random network is just the ratio of the total number of edges in the network, <span class="math notranslate nohighlight">\(m\)</span>, divided by the total number of edges possible in the network, which is <span class="math notranslate nohighlight">\(\binom n 2\)</span>! Our result is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat p &amp;= \frac{m}{\binom n 2}.
\end{align*}\]</div>
<p>Intuitively, the estimate of the probability <span class="math notranslate nohighlight">\(p\)</span> is the ratio of how many edges we see in the network, <span class="math notranslate nohighlight">\(m\)</span>, and how many edges we could have seen <span class="math notranslate nohighlight">\(\binom n 2\)</span>! To bring this back to our coin flip example, this is like we are saying that there is a single coin. We flip the coin once for every possible edge between those pairs of communities, <span class="math notranslate nohighlight">\(\binom n 2\)</span>. When that coin lands on heads, that particular edge is determined to exist, and when it lands on tails, that edge does not exist. Our best guess, then, is just to count the number of heads we obtained, <span class="math notranslate nohighlight">\(m\)</span>, and divide by the number of coin flips we made, <span class="math notranslate nohighlight">\(\binom n 2\)</span>.</p>
<p>Let’s work on an example. We will use a realization of a random network which is ER, with <span class="math notranslate nohighlight">\(40\)</span> nodes and an edge probability of <span class="math notranslate nohighlight">\(0.2\)</span>. We begin by simulating and visualizing the appropriate network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">er_np</span>
<span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Simulated ER(0.2)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/estimating-parameters_mle_2_0.png" src="../../_images/estimating-parameters_mle_2_0.png" />
</div>
</div>
<p>Next, we fit the appropriate model, from graspologic, and plot the estimated probability matrix <span class="math notranslate nohighlight">\(\hat P\)</span> against the true probability matrix <span class="math notranslate nohighlight">\(P\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.models</span> <span class="kn">import</span> <span class="n">EREstimator</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">EREstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">Phat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">p_mat_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">Phat</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$\hat P_</span><span class="si">{ER}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">P</span> <span class="o">=</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>  <span class="c1"># default entries to 0.2</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">P</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P_</span><span class="si">{ER}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Phat</span> <span class="o">-</span> <span class="n">P</span><span class="p">),</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|\hat P_</span><span class="si">{ER}</span><span class="s2"> - P_</span><span class="si">{ER}</span><span class="s2">|$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/estimating-parameters_mle_5_0.png" src="../../_images/estimating-parameters_mle_5_0.png" />
</div>
</div>
<p>Not half bad! The estimated probability matrix <span class="math notranslate nohighlight">\(\hat P\)</span> looks extremely similar to the true probability matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
</div>
<div class="section" id="stochastic-block-model">
<h2>Stochastic Block Model<a class="headerlink" href="#stochastic-block-model" title="Permalink to this headline">¶</a></h2>
<p>The Stochastic Block Model also has a single parameter: the block matrix, <span class="math notranslate nohighlight">\(B\)</span>, whose entries <span class="math notranslate nohighlight">\(b_{kk'}\)</span> denote the probabilities of edges existing or not existing between pairs of communities in the Stochastic Block Model. When we apply the method of MLE to the SBM, what we find is that, where <span class="math notranslate nohighlight">\(m_{kk'}\)</span> is the total number of edges between nodes in communities <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k'\)</span>, and <span class="math notranslate nohighlight">\(n_{kk'}\)</span> is the number of edges possible between nodes in communities <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k'\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \hat b_{kk'} = \frac{m_{kk'}}{n_{kk'}}.
\end{align*}\]</div>
<p>Intuitively, the estimate of the block probability <span class="math notranslate nohighlight">\(b_{kk'}\)</span> is the ratio of how many edges we see between communities <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k'\)</span> <span class="math notranslate nohighlight">\(m_{kk'}\)</span> and how many edges we could have seen <span class="math notranslate nohighlight">\(n_{kk'}\)</span>! To bring this back to our coin flip example, this is like we are saying that there is one coin called coin <span class="math notranslate nohighlight">\((k, k')\)</span> for each pair of communities in our network. We flip each coin once for every possible edge between those pairs of communities, <span class="math notranslate nohighlight">\(n_{kk'}\)</span>. When that coin lands on heads, that particular edge is determined to exist, and when it lands on tails, that edge does not exist. Our best guess, then, is just to count the number of heads we obtained, <span class="math notranslate nohighlight">\(m_{kk'}\)</span>, and divide by the number of coin flips we made, <span class="math notranslate nohighlight">\(n_{kk'}\)</span>.</p>
<p>Let’s work through an example network, with 20 nodes in each community, and a block matrix of:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    B &amp;= \begin{bmatrix}
        .8 &amp; .2 \\
        .2 &amp; .8
    \end{bmatrix}
\end{align*}\]</div>
<p>Which corresponds to a probability matrix <span class="math notranslate nohighlight">\(P\)</span> where each entry is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    p_{ij} &amp;= \begin{cases}
    0.8 &amp; i, j \leq 20 \text{ or }i, j \geq 20 \\
    0.2 &amp; \text{otherwise}
    \end{cases}
\end{align*}\]</div>
<p>We begin by simulating an appropriate SBM:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>

<span class="n">n</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">.8</span><span class="p">,</span> <span class="mf">.2</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">.8</span><span class="p">]]</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Simulated SBM(B)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/estimating-parameters_mle_8_0.png" src="../../_images/estimating-parameters_mle_8_0.png" />
</div>
</div>
<p>Next, let’s fit an appropriate SBM, and investigate the estimate of <span class="math notranslate nohighlight">\(B\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.models</span> <span class="kn">import</span> <span class="n">SBMEstimator</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SBMEstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">Bhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">block_p_</span>
<span class="n">Phat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">p_mat_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">Bhat</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$\hat B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">),</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$B_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Bhat</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">)),</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|\hat B_</span><span class="si">{SBM}</span><span class="s2"> - B_</span><span class="si">{SBM}</span><span class="s2">|$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/estimating-parameters_mle_11_0.png" src="../../_images/estimating-parameters_mle_11_0.png" />
</div>
</div>
<p>And our estimate <span class="math notranslate nohighlight">\(\hat B\)</span> is very similar to the true block matrix <span class="math notranslate nohighlight">\(B\)</span>. This is further reflected by looking at the probability matrix, like we did for the ER example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">Phat</span><span class="p">,</span>
        <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$\hat P_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">P</span> <span class="o">=</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">n</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">n</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># default entries to 0.2</span>
<span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.8</span>  <span class="c1"># B11</span>
<span class="n">P</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">40</span><span class="p">,</span><span class="mi">20</span><span class="p">:</span><span class="mi">40</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.8</span>  <span class="c1"># B22</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># loopless</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">P</span><span class="p">,</span>
        <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$P_</span><span class="si">{SBM}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Phat</span> <span class="o">-</span> <span class="n">P</span><span class="p">),</span>
        <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$|\hat P_</span><span class="si">{SBM}</span><span class="s2"> - P_</span><span class="si">{SBM}</span><span class="s2">|$&quot;</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">fig</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/estimating-parameters_mle_13_0.png" src="../../_images/estimating-parameters_mle_13_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Alexander Russell Loftus<br/>
        
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>